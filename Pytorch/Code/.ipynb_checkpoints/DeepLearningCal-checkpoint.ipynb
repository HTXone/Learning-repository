{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DeepLearningCal\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "class MLP(nn.Block):\n",
    "    #声明带有模型参数的层\n",
    "    def __init__(self,**kwargs):\n",
    "        #调用MLP父类Block的构造函数来进行必要的初始化。这样在构造实例时还可以指定其他函数\n",
    "        #参数,如模型参数的访问，初始化和共享\n",
    "        super(MLP,self).__init__(**kwargs)\n",
    "        self.hidden = nn.Dense(256,activation='relu') #隐藏层\n",
    "        self.output = nn.Dense(10)  #输出层\n",
    "        \n",
    "    #定义模型的前向运算，即如何根据输入x计算返回所需要的模型输出\n",
    "    def forward(self,x):\n",
    "        return self.output(self.hidden(x))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.09543004  0.04614332 -0.00286655 -0.07790346 -0.05130241  0.02942038\n",
       "   0.08696645 -0.0190793  -0.04122177  0.05088576]\n",
       " [ 0.0769287   0.03099706  0.00856576 -0.044672   -0.06926838  0.09132431\n",
       "   0.06786592 -0.06187843 -0.03436674  0.04234696]]\n",
       "<NDArray 2x10 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#通过MLP实例化网络\n",
    "X  = nd.random.uniform(shape=(2,20))\n",
    "net = MLP()\n",
    "net.initialize()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MySequential(nn.Block):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(MySequential,self).__init__(**kwargs)\n",
    "    \n",
    "    def add(self,block):\n",
    "        #block是一个Block子类实例，假设它有一个独一无二的名字。我们将它保存在Block类的\n",
    "        # 成员变量_children⾥，其类型是OrderedDict。当MySequential实例调⽤\n",
    "        # initialize函数时，系统会⾃动对_children⾥所有成员初始化\n",
    "        self._children[block.name] = block\n",
    "    def forward(self,x):\n",
    "        #OrderedDict保证会按照成员添加时的顺序遍历成员\n",
    "        for block in self._children.values():\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.00362229  0.00633331  0.03201145 -0.01369375  0.10336448 -0.0350802\n",
       "  -0.00032165 -0.01676024  0.06978628  0.01303309]\n",
       " [ 0.03871717  0.02608212  0.03544958 -0.02521311  0.11005436 -0.01430663\n",
       "  -0.03052467 -0.03852826  0.06321152  0.0038594 ]]\n",
       "<NDArray 2x10 @cpu(0)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = MySequential()\n",
    "net.add(nn.Dense(256, activation='relu'))\n",
    "net.add(nn.Dense(10))\n",
    "net.initialize()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FancyMLP(nn.Block):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(FancyMLP,self).__init__(**kwargs)\n",
    "        #使用get_constant创建的随机权重参数不在训练中被迭代（常量）\n",
    "        self.rand_weight = self.params.get_constant('rand_weight',nd.random.uniform(shape=(20,20)))\n",
    "        self.dense = nn.Dense(20,activation='relu')\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.dense(x)\n",
    "        #使用创建的常数参数，以及NDArrayd的relu函数和dot函数\n",
    "        x = nd.relu(nd.dot(x,self.rand_weight.data())+1)\n",
    "        #复用全连接层，等价于两个全连接共享参数\n",
    "        x = self.dense(x)\n",
    "        #控制流，这里调用asscalar函数来返回标量进行比较\n",
    "        while x.norm().asscalar() > 1:\n",
    "            x /=2\n",
    "        if x.norm().asscalar() < 0.8:\n",
    "            x*=10\n",
    "        return x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[21.028353]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FancyMLP()\n",
    "net.initialize()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[20.43586]\n",
       "<NDArray 1 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(nn.Block):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(NestMLP,self).__init__(**kwargs)\n",
    "        self.net = nn.Sequential()\n",
    "        self.net.add(nn.Dense(64, activation='relu'),\n",
    "                            nn.Dense(32, activation='relu'))\n",
    "        self.dense = nn.Dense(16,activation='relu')\n",
    "    def forward(self,x):\n",
    "        return self.dense(self.net(x))\n",
    "net = nn.Sequential()\n",
    "net.add(NestMLP(),nn.Dense(20),FancyMLP())\n",
    "\n",
    "net.initialize()\n",
    "net(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#从MXNet导入init模块 七包含多种模型初始化方法\n",
    "from mxnet import init,nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256,activation = 'relu'))\n",
    "net.add(nn.Dense(10))\n",
    "\n",
    "net.initialize()  #默认初始化\n",
    "\n",
    "X = nd.random.uniform(shape=(2,20))\n",
    "Y = net(X)  #前向计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⾮⾸次对模型初始化需要指定force_reinit为真\n",
    "net.initialize(init=init.Normal(sigma=0.01), force_reinit=True)\n",
    "#net[0].weight.data()[0]\n",
    "\n",
    "#下⾯使⽤常数来初始化权重参数\n",
    "net.initialize(init=init.Constant(1), force_reinit=True)\n",
    "#net[0].weight.data()[0]\n",
    "\n",
    "#使⽤Xavier随机初始化⽅法。\n",
    "net[0].weight.initialize(init=init.Xavier(), force_reinit=True)\n",
    "#net[0].weight.data()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init dense0_weight (256, 20)\n",
      "Init dense1_weight (10, 256)\n",
      "\n",
      "[-5.3659673  7.5773945  8.986376  -0.         8.827555   0.\n",
      "  5.9840508 -0.         0.         0.         7.4857597 -0.\n",
      " -0.         6.8910007  6.9788704 -6.1131554  0.         5.4665203\n",
      " -9.735263   9.485172 ]\n",
      "<NDArray 20 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "#自定义初始化方法\n",
    "class MyInit(init.Initializer):\n",
    "    def _init_weight(self,name,data):\n",
    "        print('Init',name,data.shape)\n",
    "        data[:] = nd.random_uniform(low = -10,high=10,shape=data.shape)\n",
    "        data *= data.abs() >= 5\n",
    "net.initialize(MyInit(),force_reinit=True)\n",
    "print(net[0].weight.data()[0])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[-4.3659673  8.5773945  9.986376   1.         9.827555   1.\n",
       "  6.9840508  1.         1.         1.         8.48576    1.\n",
       "  1.         7.8910007  7.9788704 -5.1131554  1.         6.4665203\n",
       " -8.735263  10.485172 ]\n",
       "<NDArray 20 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0].weight.set_data(net[0].weight.data()+1)\n",
    "net[0].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
       "<NDArray 8 @cpu(0)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#共享模型参数\n",
    "net = nn.Sequential()\n",
    "shared = nn.Dense(8,activation='relu')\n",
    "#使用关键字shared进行参数共享\n",
    "net.add(nn.Dense(8,activation='relu'),shared,nn.Dense(8,activation='relu',params = shared.params),nn.Dense(10))\n",
    "net.initialize()\n",
    "X = nd.random.uniform(shape=(2,20))\n",
    "net(X)\n",
    "\n",
    "net[1].weight.data()[0] == net[2].weight.data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#延后初始化\n",
    "from mxnet import init,nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "class MyInit(init.Initializer):\n",
    "    def _init_weight(self,name,data):\n",
    "        print('init',name,data.shape)\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256,activation='relu'),nn.Dense(10))\n",
    "\n",
    "net.initialize(init = MyInit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init dense0_weight (256, 20)\n",
      "init dense1_weight (10, 256)\n"
     ]
    }
   ],
   "source": [
    "#在调用模型进行计算时才进行初始化\n",
    "X = nd.random.uniform(shape=(2, 20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init dense0_weight (256, 20)\n",
      "init dense1_weight (10, 256)\n",
      "init dense2_weight (256, 20)\n",
      "init dense3_weight (10, 256)\n"
     ]
    }
   ],
   "source": [
    "#避免延后 通过对已初始化模型再次初始化时直接进行\n",
    "#在创建层时指定输入个数 系统不需要额外信息推测参数形状时也直接进行初始化\n",
    "\n",
    "net.initialize(init=MyInit(),force_reinit=True)\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(256,in_units = 20,activation='relu'))\n",
    "net.add(nn.Dense(10,in_units = 256))\n",
    "net.initialize(init=MyInit())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.367795e-10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自定义层\n",
    "from mxnet import gluon,nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "class CenteredLayer(nn.Block):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(CenteredLayer,self).__init__(**kwargs)\n",
    "    def forward(self,x):\n",
    "        return x - x.mean()\n",
    "\n",
    "layer = CenteredLayer() #实例化并做前向计算\n",
    "layer(nd.array([1,2,3,4,5]))\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(128),CenteredLayer())\n",
    "\n",
    "net.initialize()\n",
    "y = net(nd.random.uniform(shape=(4,8)))\n",
    "y.mean().asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       "  Parameter param2 (shape=(2, 3), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自定义含模型参数的层\n",
    "params = gluon.ParameterDict()\n",
    "params.get('param2',shape=(2,3))\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDense(nn.Block):\n",
    "    #units维该层的输出个数，in_units为该层输入个数\n",
    "    def __init__(self,units,in_units,**kwargs):\n",
    "        super(MyDense,self).__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight',shape=(in_units,units))\n",
    "        self.bias = self.params.get('bias',shape=(units,))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        linear = nd.dot(x,self.weight.data())+self.bias.data()\n",
    "        return nd.relu(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mydense1_ (\n",
       "  Parameter mydense1_weight (shape=(5, 3), dtype=<class 'numpy.float32'>)\n",
       "  Parameter mydense1_bias (shape=(3,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense = MyDense(units = 3,in_units=5)\n",
    "dense.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.06917784 0.01627153 0.01029644]\n",
       " [0.02602214 0.04537309 0.        ]]\n",
       "<NDArray 2x3 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense.initialize()\n",
    "dense(nd.random.uniform(shape=(2,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[0.03820475]\n",
       " [0.04035058]]\n",
       "<NDArray 2x1 @cpu(0)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(MyDense(8,in_units = 64),MyDense(1,in_units=8))\n",
    "net.initialize()\n",
    "net(nd.random.uniform(shape=(2,64)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读写和存储模型\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "x = nd.ones(3)\n",
    "nd.save('x',x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " [1. 1. 1.]\n",
       " <NDArray 3 @cpu(0)>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = nd.load('x')\n",
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(MLP,self).__init__(**kwargs)\n",
    "        self.hidden = nn.Dense(256,activation='relu')\n",
    "        self.output = nn.Dense(10)\n",
    "    def forward(self,x):\n",
    "        return self.output(self.hidden(x))\n",
    "net = MLP()\n",
    "net.initialize()\n",
    "X = nd.random.uniform(shape=(2,20))\n",
    "Y = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mlp.params'\n",
    "net.save_parameters(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = MLP()\n",
    "net2.load_parameters(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
       " [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
       "<NDArray 2x10 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2 = net2(X)\n",
    "Y2 == Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' 不是内部或外部命令，也不是可运行的程序\n",
      "或批处理文件。\n"
     ]
    }
   ],
   "source": [
    "#开启GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(cpu(0), gpu(0), gpu(1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.gluon import nn\n",
    "mx.cpu(), mx.gpu(), mx.gpu(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[1. 2. 3.]\n",
       "<NDArray 3 @gpu(0)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nd.array([1, 2, 3], ctx=mx.gpu())    #开启GPU加速\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
